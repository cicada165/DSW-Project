{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e85dcbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from skfeature.function.similarity_based import fisher_score\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# pd.set_option('max_columns', None)\n",
    "# pd.set_option('max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3505851",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4497f450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39644, 61)\n",
      "(38463, 61)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('OnlineNewsPopularity.csv')\n",
    "df.head()\n",
    "#Check Nullity\n",
    "df.isnull().sum() #It appears that the data has no null values\n",
    "#For ' n_tokens_content', if it is 0, it means that the artitle is empty, therefore, let's remove those rows\n",
    "print(df.shape)\n",
    "df = df[df[' n_tokens_content'] != 0]\n",
    "print(df.shape)\n",
    "#Drop columns that are obbiously not going to be useful\n",
    "df.drop(['url', ' timedelta', ' n_non_stop_words', ' n_non_stop_unique_tokens'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e07ff48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.382419</td>\n",
       "      <td>563.295375</td>\n",
       "      <td>0.565049</td>\n",
       "      <td>11.217872</td>\n",
       "      <td>3.394769</td>\n",
       "      <td>4.563061</td>\n",
       "      <td>1.263786</td>\n",
       "      <td>4.687892</td>\n",
       "      <td>7.215012</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098376</td>\n",
       "      <td>0.779963</td>\n",
       "      <td>-0.267493</td>\n",
       "      <td>-0.537970</td>\n",
       "      <td>-0.110801</td>\n",
       "      <td>0.280573</td>\n",
       "      <td>0.070997</td>\n",
       "      <td>0.342431</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>3355.360398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.113800</td>\n",
       "      <td>468.299538</td>\n",
       "      <td>3.573022</td>\n",
       "      <td>11.340580</td>\n",
       "      <td>3.869773</td>\n",
       "      <td>8.295365</td>\n",
       "      <td>4.164896</td>\n",
       "      <td>0.283231</td>\n",
       "      <td>1.916459</td>\n",
       "      <td>0.226021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070382</td>\n",
       "      <td>0.212509</td>\n",
       "      <td>0.121174</td>\n",
       "      <td>0.279703</td>\n",
       "      <td>0.094919</td>\n",
       "      <td>0.323561</td>\n",
       "      <td>0.264338</td>\n",
       "      <td>0.188606</td>\n",
       "      <td>0.225636</td>\n",
       "      <td>11585.968776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.114964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>259.000000</td>\n",
       "      <td>0.477419</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.496250</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.331532</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>945.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>0.542986</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.674121</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.257738</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.861901</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.193415</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>8474.000000</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>8.041534</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_tokens_title   n_tokens_content   n_unique_tokens     num_hrefs  \\\n",
       "count     38463.000000       38463.000000      38463.000000  38463.000000   \n",
       "mean         10.382419         563.295375          0.565049     11.217872   \n",
       "std           2.113800         468.299538          3.573022     11.340580   \n",
       "min           2.000000          18.000000          0.114964      0.000000   \n",
       "25%           9.000000         259.000000          0.477419      5.000000   \n",
       "50%          10.000000         423.000000          0.542986      8.000000   \n",
       "75%          12.000000         729.000000          0.611111     14.000000   \n",
       "max          23.000000        8474.000000        701.000000    304.000000   \n",
       "\n",
       "        num_self_hrefs      num_imgs    num_videos   average_token_length  \\\n",
       "count     38463.000000  38463.000000  38463.000000           38463.000000   \n",
       "mean          3.394769      4.563061      1.263786               4.687892   \n",
       "std           3.869773      8.295365      4.164896               0.283231   \n",
       "min           0.000000      0.000000      0.000000               3.600000   \n",
       "25%           1.000000      1.000000      0.000000               4.496250   \n",
       "50%           3.000000      1.000000      0.000000               4.674121   \n",
       "75%           4.000000      4.000000      1.000000               4.861901   \n",
       "max         116.000000    128.000000     91.000000               8.041534   \n",
       "\n",
       "        num_keywords   data_channel_is_lifestyle  ...   min_positive_polarity  \\\n",
       "count   38463.000000                38463.000000  ...            38463.000000   \n",
       "mean        7.215012                    0.054000  ...                0.098376   \n",
       "std         1.916459                    0.226021  ...                0.070382   \n",
       "min         1.000000                    0.000000  ...                0.000000   \n",
       "25%         6.000000                    0.000000  ...                0.050000   \n",
       "50%         7.000000                    0.000000  ...                0.100000   \n",
       "75%         9.000000                    0.000000  ...                0.100000   \n",
       "max        10.000000                    1.000000  ...                1.000000   \n",
       "\n",
       "        max_positive_polarity   avg_negative_polarity   min_negative_polarity  \\\n",
       "count            38463.000000            38463.000000            38463.000000   \n",
       "mean                 0.779963               -0.267493               -0.537970   \n",
       "std                  0.212509                0.121174                0.279703   \n",
       "min                  0.000000               -1.000000               -1.000000   \n",
       "25%                  0.600000               -0.331532               -0.714286   \n",
       "50%                  0.800000               -0.257738               -0.500000   \n",
       "75%                  1.000000               -0.193415               -0.312500   \n",
       "max                  1.000000                0.000000                0.000000   \n",
       "\n",
       "        max_negative_polarity   title_subjectivity   title_sentiment_polarity  \\\n",
       "count            38463.000000         38463.000000               38463.000000   \n",
       "mean                -0.110801             0.280573                   0.070997   \n",
       "std                  0.094919             0.323561                   0.264338   \n",
       "min                 -1.000000             0.000000                  -1.000000   \n",
       "25%                 -0.125000             0.000000                   0.000000   \n",
       "50%                 -0.100000             0.125000                   0.000000   \n",
       "75%                 -0.050000             0.500000                   0.136364   \n",
       "max                  0.000000             1.000000                   1.000000   \n",
       "\n",
       "        abs_title_subjectivity   abs_title_sentiment_polarity         shares  \n",
       "count             38463.000000                   38463.000000   38463.000000  \n",
       "mean                  0.342431                       0.154930    3355.360398  \n",
       "std                   0.188606                       0.225636   11585.968776  \n",
       "min                   0.000000                       0.000000       1.000000  \n",
       "25%                   0.166667                       0.000000     945.000000  \n",
       "50%                   0.500000                       0.000000    1400.000000  \n",
       "75%                   0.500000                       0.250000    2700.000000  \n",
       "max                   0.500000                       1.000000  843300.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef2b7bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945.0\n",
      "1400.0\n",
      "2700.0\n"
     ]
    }
   ],
   "source": [
    "#25 Percentile\n",
    "print(df[' shares'].quantile(q=0.25))\n",
    "\n",
    "#50 Percentile\n",
    "print(df[' shares'].quantile(q=0.50))\n",
    "\n",
    "#75 Percentile\n",
    "print(df[' shares'].quantile(q=0.75))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c062c28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>...</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.913725</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>711</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.393365</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.404896</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.682836</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_tokens_title   n_tokens_content   n_unique_tokens   num_hrefs  \\\n",
       "0             12.0              219.0          0.663594         4.0   \n",
       "1              9.0              255.0          0.604743         3.0   \n",
       "2              9.0              211.0          0.575130         3.0   \n",
       "3              9.0              531.0          0.503788         9.0   \n",
       "4             13.0             1072.0          0.415646        19.0   \n",
       "\n",
       "    num_self_hrefs   num_imgs   num_videos   average_token_length  \\\n",
       "0              2.0        1.0          0.0               4.680365   \n",
       "1              1.0        1.0          0.0               4.913725   \n",
       "2              1.0        1.0          0.0               4.393365   \n",
       "3              0.0        1.0          0.0               4.404896   \n",
       "4             19.0       20.0          0.0               4.682836   \n",
       "\n",
       "    num_keywords   data_channel_is_lifestyle  ...   max_positive_polarity  \\\n",
       "0            5.0                         0.0  ...                     0.7   \n",
       "1            4.0                         0.0  ...                     0.7   \n",
       "2            6.0                         0.0  ...                     1.0   \n",
       "3            7.0                         0.0  ...                     0.8   \n",
       "4            7.0                         0.0  ...                     1.0   \n",
       "\n",
       "    avg_negative_polarity   min_negative_polarity   max_negative_polarity  \\\n",
       "0               -0.350000                  -0.600               -0.200000   \n",
       "1               -0.118750                  -0.125               -0.100000   \n",
       "2               -0.466667                  -0.800               -0.133333   \n",
       "3               -0.369697                  -0.600               -0.166667   \n",
       "4               -0.220192                  -0.500               -0.050000   \n",
       "\n",
       "    title_subjectivity   title_sentiment_polarity   abs_title_subjectivity  \\\n",
       "0             0.500000                  -0.187500                 0.000000   \n",
       "1             0.000000                   0.000000                 0.500000   \n",
       "2             0.000000                   0.000000                 0.500000   \n",
       "3             0.000000                   0.000000                 0.500000   \n",
       "4             0.454545                   0.136364                 0.045455   \n",
       "\n",
       "    abs_title_sentiment_polarity   shares   popularity  \n",
       "0                       0.187500      593            0  \n",
       "1                       0.000000      711            0  \n",
       "2                       0.000000     1500            1  \n",
       "3                       0.000000     1200            0  \n",
       "4                       0.136364      505            0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert into binary classfication problem\n",
    "#Use median to create label: 0:bad 1:good\n",
    "print(df[' shares'].median())\n",
    "df[' popularity'] = df[' shares'].apply(lambda x: 0 if x <1400 else 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1066aae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>weekdays</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.663594</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.604743</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.913725</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.575130</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.393365</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.800</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.404896</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>0.415646</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.682836</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_tokens_title   n_tokens_content   n_unique_tokens   num_hrefs  \\\n",
       "0             12.0              219.0          0.663594         4.0   \n",
       "1              9.0              255.0          0.604743         3.0   \n",
       "2              9.0              211.0          0.575130         3.0   \n",
       "3              9.0              531.0          0.503788         9.0   \n",
       "4             13.0             1072.0          0.415646        19.0   \n",
       "\n",
       "    num_self_hrefs   num_imgs   num_videos   average_token_length  \\\n",
       "0              2.0        1.0          0.0               4.680365   \n",
       "1              1.0        1.0          0.0               4.913725   \n",
       "2              1.0        1.0          0.0               4.393365   \n",
       "3              0.0        1.0          0.0               4.404896   \n",
       "4             19.0       20.0          0.0               4.682836   \n",
       "\n",
       "    num_keywords  weekdays  ...   min_positive_polarity  \\\n",
       "0            5.0         0  ...                0.100000   \n",
       "1            4.0         0  ...                0.033333   \n",
       "2            6.0         0  ...                0.100000   \n",
       "3            7.0         0  ...                0.136364   \n",
       "4            7.0         0  ...                0.033333   \n",
       "\n",
       "    max_positive_polarity   avg_negative_polarity   min_negative_polarity  \\\n",
       "0                     0.7               -0.350000                  -0.600   \n",
       "1                     0.7               -0.118750                  -0.125   \n",
       "2                     1.0               -0.466667                  -0.800   \n",
       "3                     0.8               -0.369697                  -0.600   \n",
       "4                     1.0               -0.220192                  -0.500   \n",
       "\n",
       "    max_negative_polarity   title_subjectivity   title_sentiment_polarity  \\\n",
       "0               -0.200000             0.500000                  -0.187500   \n",
       "1               -0.100000             0.000000                   0.000000   \n",
       "2               -0.133333             0.000000                   0.000000   \n",
       "3               -0.166667             0.000000                   0.000000   \n",
       "4               -0.050000             0.454545                   0.136364   \n",
       "\n",
       "    abs_title_subjectivity   abs_title_sentiment_polarity   popularity  \n",
       "0                 0.000000                       0.187500            0  \n",
       "1                 0.500000                       0.000000            0  \n",
       "2                 0.500000                       0.000000            1  \n",
       "3                 0.500000                       0.000000            0  \n",
       "4                 0.045455                       0.136364            0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some of the features are related to each other such as ' weekday_is_monday' and ' weekday_is_tuesday' and ' data_channel_is_lifestyle' and ' data_channel_is_entertainment'. This violates non-multicollinearity of model such as linear regression\n",
    "#Merging \n",
    "dayMerge = df[[' weekday_is_monday',' weekday_is_tuesday',' weekday_is_wednesday',' weekday_is_thursday',' weekday_is_friday',' weekday_is_saturday',' weekday_is_sunday', ]]\n",
    "day_arr = []\n",
    "for r in list(range(dayMerge.shape[0])):\n",
    "    for c in list(range(dayMerge.shape[1])):\n",
    "        if ((c==0) and (dayMerge.iloc[r,c])==1):\n",
    "            day_arr.append(0)\n",
    "        elif ((c==1) and (dayMerge.iloc[r,c])==1):\n",
    "            day_arr.append(1)\n",
    "        elif ((c==2) and (dayMerge.iloc[r,c])==1):\n",
    "            day_arr.append(2)\n",
    "        elif ((c==3) and (dayMerge.iloc[r,c])==1):\n",
    "            day_arr.append(3)\n",
    "        elif ((c==4) and (dayMerge.iloc[r,c])==1):\n",
    "            day_arr.append(4)\n",
    "        elif ((c==5) and (dayMerge.iloc[r,c])==1):\n",
    "            day_arr.append(5) \n",
    "        elif ((c==6) and (dayMerge.iloc[r,c])==1):\n",
    "            day_arr.append(6)\n",
    "            \n",
    "channelMerge=df[[' data_channel_is_lifestyle',' data_channel_is_entertainment' ,' data_channel_is_bus',\n",
    "                        ' data_channel_is_socmed' ,' data_channel_is_tech',' data_channel_is_world' ]]\n",
    "\n",
    "channel_arr = []\n",
    "\n",
    "for r in list(range(channelMerge.shape[0])):\n",
    "    if (((channelMerge.iloc[r,0])==0) and ((channelMerge.iloc[r,1])==0) and ((channelMerge.iloc[r,2])==0) and ((channelMerge.iloc[r,3])==0) and ((channelMerge.iloc[r,4])==0) and ((channelMerge.iloc[r,5])==0)):\n",
    "        channel_arr.append(6)\n",
    "    for c in list(range(channelMerge.shape[1])):\n",
    "        if ((c==0) and (channelMerge.iloc[r,c])==1):\n",
    "            channel_arr.append(0)\n",
    "        elif ((c==1) and (channelMerge.iloc[r,c])==1):\n",
    "            channel_arr.append(1)\n",
    "        elif ((c==2) and (channelMerge.iloc[r,c])==1):\n",
    "            channel_arr.append(2)\n",
    "        elif ((c==3) and (channelMerge.iloc[r,c])==1):\n",
    "            channel_arr.append(3)\n",
    "        elif ((c==4) and (channelMerge.iloc[r,c])==1):\n",
    "            channel_arr.append(4)\n",
    "        elif ((c==5) and (channelMerge.iloc[r,c])==1):\n",
    "            channel_arr.append(5)\n",
    "            \n",
    "df.insert(loc=11, column='weekdays', value=day_arr)\n",
    "df.insert(loc=12, column='data_channel', value=channel_arr)\n",
    "\n",
    "df.drop(labels=[' data_channel_is_lifestyle',' data_channel_is_entertainment' ,' data_channel_is_bus',\n",
    "                  ' data_channel_is_socmed' ,' data_channel_is_tech',' data_channel_is_world', \n",
    "                  ' weekday_is_monday',' weekday_is_tuesday',' weekday_is_wednesday', \n",
    "                  ' weekday_is_thursday', ' weekday_is_friday',' weekday_is_saturday' ,' weekday_is_sunday', ' shares'], axis = 1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e92c0255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Popularity  No of articles\n",
      "0           0           17999\n",
      "1           1           20464\n",
      "   weekdays  count\n",
      "0         0   6471\n",
      "1         1   7171\n",
      "2         2   7205\n",
      "3         3   7052\n",
      "4         4   5538\n",
      "5         5   2369\n",
      "6         6   2657\n",
      "   data_channel  count\n",
      "0             0   2077\n",
      "1             1   6856\n",
      "2             2   6235\n",
      "3             3   2311\n",
      "4             4   7325\n",
      "5             5   8168\n",
      "6             6   5491\n"
     ]
    }
   ],
   "source": [
    "#Check Class Balance\n",
    "class_counts = df.groupby(' popularity').size().reset_index()\n",
    "class_counts.columns = ['Popularity','No of articles']\n",
    "print(class_counts)\n",
    "\n",
    "weekdays_data = df.groupby('weekdays').size().reset_index()\n",
    "weekdays_data.columns = ['weekdays','count']\n",
    "print(weekdays_data)\n",
    "\n",
    "channel_data = df.groupby('data_channel').size().reset_index()\n",
    "channel_data.columns = ['data_channel','count']\n",
    "print(channel_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c881c3",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8446a09d",
   "metadata": {},
   "source": [
    "## L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589991f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attempting Lasso(L1) feature selection\n",
    "# shares data is not needed for classification\n",
    "X = df.drop(labels=['popularity'], axis = 1, inplace=False)\n",
    "y = df['popularity']\n",
    "X= pd.get_dummies(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "# Standardize the train and test sample\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X_train)\n",
    "\n",
    "# Perform GridSearchCV to tune best-fit LR model\n",
    "param = {'C': [10**-2,10**-1,10**0,10**1,10**2]}\n",
    "\n",
    "lr_model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Redundant Feature Count: \", sum(lr_model.coef_[0]==0))\n",
    "print(\"Redundant Feature Names: \", list(pd.Series(X_train.columns)[list(lr_model.coef_[0]==0)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8555ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=[' global_rate_negative_words', ' avg_positive_polarity', ' global_sentiment_polarity', ' avg_negative_polarity', ' max_negative_polarity'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d101c68d",
   "metadata": {},
   "source": [
    "## Fisher Score Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a8a165f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/skfeature/utility/construct_W.py:194: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  class_idx_all = class_idx[:, np.newaxis] & class_idx[np.newaxis, :]\n",
      "/opt/anaconda3/lib/python3.8/site-packages/skfeature/utility/construct_W.py:194: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  class_idx_all = class_idx[:, np.newaxis] & class_idx[np.newaxis, :]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-edf815ac3e07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity_based\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfisher_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfisher_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfisher_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mranks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/skfeature/function/similarity_based/fisher_score.py\u001b[0m in \u001b[0;36mfisher_score\u001b[0;34m(X, y, mode)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;31m# compute the numerator of Lr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mD_prime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36mtodense\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mshares\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         \"\"\"\n\u001b[0;32m--> 864\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/scipy/sparse/lil.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m                 \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# scaler = StandardScaler()\n",
    "# X = df.drop(labels=[' popularity'], axis = 1, inplace=False)\n",
    "# y = df[' popularity']\n",
    "# X = pd.get_dummies(X)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = False)\n",
    "# X_std = scaler.fit_transform(X_train)\n",
    "# from skfeature.function.similarity_based import fisher_score\n",
    "# ranks = fisher_score.fisher_score(X_std, y_train)\n",
    "# print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# feat_importance = pd.Series(ranks, X.columns[0: len(X.columns)])\n",
    "# feat_importance.plot(kind='barh', color = 'teal')\n",
    "# fig = plt.figure() \n",
    "# fig.set_size_inches(50, 50)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077bbbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_lst = []\n",
    "# score_map = []\n",
    "# for idx, val in enumerate(ranks):\n",
    "#     if val < 5:\n",
    "#         idx_lst.append(idx)\n",
    "#         score_map.append((idx, val))\n",
    "# print(score_map)\n",
    "# print(\"Redundant Feature Names: \", list(pd.Series(X_train.columns)[idx_lst]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc1db7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(labels=list(pd.Series(X_train.columns)[idx_lst]), axis = 1, inplace=True)\n",
    "df.drop(labels=[' global_rate_negative_words', ' avg_positive_polarity', ' global_sentiment_polarity', ' avg_negative_polarity', ' max_negative_polarity'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0cc2b3",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4389c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "X_std = scaler.fit_transform(df)\n",
    "df = pd.DataFrame(X_std, columns = df.columns[0: len(df.columns)])\n",
    "X = df.drop(labels=[' popularity'], axis = 1, inplace=False)\n",
    "y = df[' popularity']\n",
    "labelEn = LabelEncoder()\n",
    "y = labelEn.fit_transform(y)\n",
    "# class_names = labelEn.classes_\n",
    "\n",
    "X= pd.get_dummies(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc17d3d6",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf7cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm = SVC(gamma='auto')\n",
    "# svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfcddb0",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da3d715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=7000)\n",
    "# logistic_regression.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0daf27",
   "metadata": {},
   "source": [
    "## Tree-based Method: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9389e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=50, n_estimators=1000, n_jobs=-1,\n",
       "                       random_state=666)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classfication = RandomForestClassifier(n_estimators=1000, n_jobs=-1, max_depth=50,random_state=666)\n",
    "rf_classfication.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3554e174",
   "metadata": {},
   "source": [
    "## Tree-based Method: XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb9970e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=5, max_leaves=0, min_child_weight=6,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=400,\n",
       "              n_jobs=8, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgboost = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
    "             min_child_weight=6, monotone_constraints='()',\n",
    "       n_estimators=400, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
    "            reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "xgboost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d34effa",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd582b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch as T\n",
    "# class Net(T.nn.Module):\n",
    "#   def __init__(self):\n",
    "#     super(Net, self).__init__()\n",
    "#     self.hid1 = T.nn.Linear(8, 10)  # 8-(10-10)-1\n",
    "#     self.hid2 = T.nn.Linear(10, 10)\n",
    "#     self.oupt = T.nn.Linear(10, 1)\n",
    "\n",
    "#     T.nn.init.xavier_uniform_(self.hid1.weight)\n",
    "#     T.nn.init.zeros_(self.hid1.bias)\n",
    "#     T.nn.init.xavier_uniform_(self.hid2.weight)\n",
    "#     T.nn.init.zeros_(self.hid2.bias)\n",
    "#     T.nn.init.xavier_uniform_(self.oupt.weight)\n",
    "#     T.nn.init.zeros_(self.oupt.bias)\n",
    "\n",
    "#   def forward(self, x):\n",
    "#     z = T.relu(self.hid1(x))\n",
    "#     z = T.relu(self.hid2(z))\n",
    "#     z = self.oupt(z)  # no activation\n",
    "#     return z\n",
    "\n",
    "# bat_size = 10\n",
    "# net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5bb3bd",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e40e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluateing Logistic Regression\n",
    "# y_pred = logistic_regression.predict(X_test)\n",
    "# print(\"F1 Score: \",f1_score(y_test, y_pred, average='macro'))\n",
    "#print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "#F1 Score:  0.31860939565338836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cb65e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.6819314882506857\n",
      "Accuracy:  0.6820348383742092\n"
     ]
    }
   ],
   "source": [
    "#Evaluating RF\n",
    "y_pred = rf_classfication.predict(X_test)\n",
    "print(\"F1 Score: \",f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f865d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating SVM\n",
    "# y_pred = svm.predict(X_test)\n",
    "# print(\"F1 Score: \",f1_score(y_test, y_pred, average='macro'))\n",
    "#print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "#F1 Score:  0.10067998398348055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0944dea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.6763074207537915\n",
      "Accuracy:  0.6764017679174972\n"
     ]
    }
   ],
   "source": [
    "#Evaluating XG Boost\n",
    "y_pred = xgboost.predict(X_test)\n",
    "print(\"F1 Score: \",f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8968243c",
   "metadata": {},
   "source": [
    "# Conclusions and Findings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
