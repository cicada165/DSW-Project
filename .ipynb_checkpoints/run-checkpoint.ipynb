{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e85dcbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score, accuracy_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from skfeature.function.similarity_based import fisher_score\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# pd.set_option('max_columns', None)\n",
    "# pd.set_option('max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3505851",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4497f450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39644, 61)\n",
      "(38463, 61)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('OnlineNewsPopularity.csv')\n",
    "df.head()\n",
    "#Check Nullity\n",
    "df.isnull().sum() #It appears that the data has no null values\n",
    "#For ' n_tokens_content', if it is 0, it means that the artitle is empty, therefore, let's remove those rows\n",
    "print(df.shape)\n",
    "df = df[df[' n_tokens_content'] != 0]\n",
    "print(df.shape)\n",
    "#Drop columns that are obbiously not going to be useful\n",
    "df.drop(['url', ' timedelta', ' n_non_stop_words', ' n_non_stop_unique_tokens'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07ff48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "      <td>38463.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.382419</td>\n",
       "      <td>563.295375</td>\n",
       "      <td>0.565049</td>\n",
       "      <td>11.217872</td>\n",
       "      <td>3.394769</td>\n",
       "      <td>4.563061</td>\n",
       "      <td>1.263786</td>\n",
       "      <td>4.687892</td>\n",
       "      <td>7.215012</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098376</td>\n",
       "      <td>0.779963</td>\n",
       "      <td>-0.267493</td>\n",
       "      <td>-0.537970</td>\n",
       "      <td>-0.110801</td>\n",
       "      <td>0.280573</td>\n",
       "      <td>0.070997</td>\n",
       "      <td>0.342431</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>3355.360398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.113800</td>\n",
       "      <td>468.299538</td>\n",
       "      <td>3.573022</td>\n",
       "      <td>11.340580</td>\n",
       "      <td>3.869773</td>\n",
       "      <td>8.295365</td>\n",
       "      <td>4.164896</td>\n",
       "      <td>0.283231</td>\n",
       "      <td>1.916459</td>\n",
       "      <td>0.226021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070382</td>\n",
       "      <td>0.212509</td>\n",
       "      <td>0.121174</td>\n",
       "      <td>0.279703</td>\n",
       "      <td>0.094919</td>\n",
       "      <td>0.323561</td>\n",
       "      <td>0.264338</td>\n",
       "      <td>0.188606</td>\n",
       "      <td>0.225636</td>\n",
       "      <td>11585.968776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.114964</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>259.000000</td>\n",
       "      <td>0.477419</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.496250</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>-0.331532</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>945.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>0.542986</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.674121</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>-0.257738</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.861901</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.193415</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>8474.000000</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>8.041534</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>843300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_tokens_title   n_tokens_content   n_unique_tokens     num_hrefs  \\\n",
       "count     38463.000000       38463.000000      38463.000000  38463.000000   \n",
       "mean         10.382419         563.295375          0.565049     11.217872   \n",
       "std           2.113800         468.299538          3.573022     11.340580   \n",
       "min           2.000000          18.000000          0.114964      0.000000   \n",
       "25%           9.000000         259.000000          0.477419      5.000000   \n",
       "50%          10.000000         423.000000          0.542986      8.000000   \n",
       "75%          12.000000         729.000000          0.611111     14.000000   \n",
       "max          23.000000        8474.000000        701.000000    304.000000   \n",
       "\n",
       "        num_self_hrefs      num_imgs    num_videos   average_token_length  \\\n",
       "count     38463.000000  38463.000000  38463.000000           38463.000000   \n",
       "mean          3.394769      4.563061      1.263786               4.687892   \n",
       "std           3.869773      8.295365      4.164896               0.283231   \n",
       "min           0.000000      0.000000      0.000000               3.600000   \n",
       "25%           1.000000      1.000000      0.000000               4.496250   \n",
       "50%           3.000000      1.000000      0.000000               4.674121   \n",
       "75%           4.000000      4.000000      1.000000               4.861901   \n",
       "max         116.000000    128.000000     91.000000               8.041534   \n",
       "\n",
       "        num_keywords   data_channel_is_lifestyle  ...   min_positive_polarity  \\\n",
       "count   38463.000000                38463.000000  ...            38463.000000   \n",
       "mean        7.215012                    0.054000  ...                0.098376   \n",
       "std         1.916459                    0.226021  ...                0.070382   \n",
       "min         1.000000                    0.000000  ...                0.000000   \n",
       "25%         6.000000                    0.000000  ...                0.050000   \n",
       "50%         7.000000                    0.000000  ...                0.100000   \n",
       "75%         9.000000                    0.000000  ...                0.100000   \n",
       "max        10.000000                    1.000000  ...                1.000000   \n",
       "\n",
       "        max_positive_polarity   avg_negative_polarity   min_negative_polarity  \\\n",
       "count            38463.000000            38463.000000            38463.000000   \n",
       "mean                 0.779963               -0.267493               -0.537970   \n",
       "std                  0.212509                0.121174                0.279703   \n",
       "min                  0.000000               -1.000000               -1.000000   \n",
       "25%                  0.600000               -0.331532               -0.714286   \n",
       "50%                  0.800000               -0.257738               -0.500000   \n",
       "75%                  1.000000               -0.193415               -0.312500   \n",
       "max                  1.000000                0.000000                0.000000   \n",
       "\n",
       "        max_negative_polarity   title_subjectivity   title_sentiment_polarity  \\\n",
       "count            38463.000000         38463.000000               38463.000000   \n",
       "mean                -0.110801             0.280573                   0.070997   \n",
       "std                  0.094919             0.323561                   0.264338   \n",
       "min                 -1.000000             0.000000                  -1.000000   \n",
       "25%                 -0.125000             0.000000                   0.000000   \n",
       "50%                 -0.100000             0.125000                   0.000000   \n",
       "75%                 -0.050000             0.500000                   0.136364   \n",
       "max                  0.000000             1.000000                   1.000000   \n",
       "\n",
       "        abs_title_subjectivity   abs_title_sentiment_polarity         shares  \n",
       "count             38463.000000                   38463.000000   38463.000000  \n",
       "mean                  0.342431                       0.154930    3355.360398  \n",
       "std                   0.188606                       0.225636   11585.968776  \n",
       "min                   0.000000                       0.000000       1.000000  \n",
       "25%                   0.166667                       0.000000     945.000000  \n",
       "50%                   0.500000                       0.000000    1400.000000  \n",
       "75%                   0.500000                       0.250000    2700.000000  \n",
       "max                   0.500000                       1.000000  843300.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef2b7bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945.0\n",
      "1400.0\n",
      "2700.0\n"
     ]
    }
   ],
   "source": [
    "#25 Percentile\n",
    "print(df[' shares'].quantile(q=0.25))\n",
    "\n",
    "#50 Percentile\n",
    "print(df[' shares'].quantile(q=0.50))\n",
    "\n",
    "#75 Percentile\n",
    "print(df[' shares'].quantile(q=0.75))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c062c28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38463, 57)\n"
     ]
    }
   ],
   "source": [
    "#Convert ' share' to categorical\n",
    "# <25 percentile: poor, 25-75 percentile: average, 75-100 percentile: good\n",
    "print(df.shape)\n",
    "share_label = list()\n",
    "for share in df[' shares']:\n",
    "        \n",
    "    if share <= 946:\n",
    "        share_label.append(0)#Very Poor\n",
    "    elif share > 946 and share <= 1400:\n",
    "        share_label.append(1)#Poor\n",
    "    elif share >1400 and share <= 2800:\n",
    "        share_label.append(2)#Above Average\n",
    "    else:\n",
    "        share_label.append(3)#Good\n",
    "        \n",
    "        \n",
    "\n",
    "# Update this class label into the dataframe\n",
    "df['popularity'] = share_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1066aae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Some of the features are related to each other such as ' weekday_is_monday' and ' weekday_is_tuesday' and ' data_channel_is_lifestyle' and ' data_channel_is_entertainment'. This violates non-multicollinearity of model such as linear regression\n",
    "#Merging \n",
    "dayMerge = df[[' weekday_is_monday',' weekday_is_tuesday',' weekday_is_wednesday',' weekday_is_thursday',' weekday_is_friday',' weekday_is_saturday',' weekday_is_sunday', ]]\n",
    "day_arr = []\n",
    "for r in list(range(dayMerge.shape[0])):\n",
    "    for c in list(range(dayMerge.shape[1])):\n",
    "        if ((c==0) and (dayMerge.iloc[r,c])==1):\n",
    "            day_arr.append(0)\n",
    "        elif ((c==1) and (dayMerge.iloc[r,c])==1):\n",
    "            day_arr.append(1)\n",
    "        elif ((c==2) and (dayMerge.iloc[r,c])==1):\n",
    "            day_arr.append(2)\n",
    "        elif ((c==3) and (dayMerge.iloc[r,c])==1):\n",
    "            day_arr.append(3)\n",
    "        elif ((c==4) and (dayMerge.iloc[r,c])==1):\n",
    "            day_arr.append(4)\n",
    "        elif ((c==5) and (dayMerge.iloc[r,c])==1):\n",
    "            day_arr.append(5) \n",
    "        elif ((c==6) and (dayMerge.iloc[r,c])==1):\n",
    "            day_arr.append(6)\n",
    "            \n",
    "channelMerge=df[[' data_channel_is_lifestyle',' data_channel_is_entertainment' ,' data_channel_is_bus',\n",
    "                        ' data_channel_is_socmed' ,' data_channel_is_tech',' data_channel_is_world' ]]\n",
    "\n",
    "channel_arr = []\n",
    "\n",
    "for r in list(range(channelMerge.shape[0])):\n",
    "    if (((channelMerge.iloc[r,0])==0) and ((channelMerge.iloc[r,1])==0) and ((channelMerge.iloc[r,2])==0) and ((channelMerge.iloc[r,3])==0) and ((channelMerge.iloc[r,4])==0) and ((channelMerge.iloc[r,5])==0)):\n",
    "        channel_arr.append(6)\n",
    "    for c in list(range(channelMerge.shape[1])):\n",
    "        if ((c==0) and (channelMerge.iloc[r,c])==1):\n",
    "            channel_arr.append(0)\n",
    "        elif ((c==1) and (channelMerge.iloc[r,c])==1):\n",
    "            channel_arr.append(1)\n",
    "        elif ((c==2) and (channelMerge.iloc[r,c])==1):\n",
    "            channel_arr.append(2)\n",
    "        elif ((c==3) and (channelMerge.iloc[r,c])==1):\n",
    "            channel_arr.append(3)\n",
    "        elif ((c==4) and (channelMerge.iloc[r,c])==1):\n",
    "            channel_arr.append(4)\n",
    "        elif ((c==5) and (channelMerge.iloc[r,c])==1):\n",
    "            channel_arr.append(5)\n",
    "            \n",
    "df.insert(loc=11, column='weekdays', value=day_arr)\n",
    "df.insert(loc=12, column='data_channel', value=channel_arr)\n",
    "\n",
    "df.drop(labels=[' data_channel_is_lifestyle',' data_channel_is_entertainment' ,' data_channel_is_bus',\n",
    "                  ' data_channel_is_socmed' ,' data_channel_is_tech',' data_channel_is_world', \n",
    "                  ' weekday_is_monday',' weekday_is_tuesday',' weekday_is_wednesday', \n",
    "                  ' weekday_is_thursday', ' weekday_is_friday',' weekday_is_saturday' ,' weekday_is_sunday', ' shares'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e92c0255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Popularity  No of articles\n",
      "0           0            9661\n",
      "1           1            9890\n",
      "2           2            9660\n",
      "3           3            9252\n",
      "   weekdays  count\n",
      "0         0   6471\n",
      "1         1   7171\n",
      "2         2   7205\n",
      "3         3   7052\n",
      "4         4   5538\n",
      "5         5   2369\n",
      "6         6   2657\n",
      "   data_channel  count\n",
      "0             0   2077\n",
      "1             1   6856\n",
      "2             2   6235\n",
      "3             3   2311\n",
      "4             4   7325\n",
      "5             5   8168\n",
      "6             6   5491\n"
     ]
    }
   ],
   "source": [
    "#Check Class Balance\n",
    "class_counts = df.groupby('popularity').size().reset_index()\n",
    "class_counts.columns = ['Popularity','No of articles']\n",
    "print(class_counts)\n",
    "\n",
    "weekdays_data = df.groupby('weekdays').size().reset_index()\n",
    "weekdays_data.columns = ['weekdays','count']\n",
    "print(weekdays_data)\n",
    "\n",
    "channel_data = df.groupby('data_channel').size().reset_index()\n",
    "channel_data.columns = ['data_channel','count']\n",
    "print(channel_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c881c3",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8446a09d",
   "metadata": {},
   "source": [
    "## L1 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "589991f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redundant Feature Count:  2\n",
      "Redundant Feature Names:  [' global_rate_positive_words', ' global_rate_negative_words']\n"
     ]
    }
   ],
   "source": [
    "#Attempting Lasso(L1) feature selection\n",
    "# shares data is not needed for classification\n",
    "X = df.drop(labels=['popularity'], axis = 1, inplace=False)\n",
    "y = df['popularity']\n",
    "X= pd.get_dummies(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "# Standardize the train and test sample\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X_train)\n",
    "\n",
    "# Perform GridSearchCV to tune best-fit LR model\n",
    "param = {'C': [10**-2,10**-1,10**0,10**1,10**2]}\n",
    "\n",
    "lr_model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Redundant Feature Count: \", sum(lr_model.coef_[0]==0))\n",
    "print(\"Redundant Feature Names: \", list(pd.Series(X_train.columns)[list(lr_model.coef_[0]==0)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8555ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels=[' global_rate_negative_words', ' avg_positive_polarity', ' global_sentiment_polarity', ' avg_negative_polarity', ' max_negative_polarity'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbc5df1",
   "metadata": {},
   "source": [
    "## PCA Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb4e591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d101c68d",
   "metadata": {},
   "source": [
    "## Fisher Score Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a8a165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = fisher_score.fisher_score(X_std, y_train)\n",
    "\n",
    "# feat_importance = pd.Series(scores, X_std.colums[:])\n",
    "# feat_importance.plot(kind='barh', color = 'teal')\n",
    "# plt.show()\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0cc2b3",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4389c64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = df.drop(labels=['popularity'], axis = 1, inplace=False)\n",
    "y = df['popularity']\n",
    "labelEn = LabelEncoder()\n",
    "y = labelEn.fit_transform(y)\n",
    "# class_names = labelEn.classes_\n",
    "\n",
    "X= pd.get_dummies(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc17d3d6",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecf7cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm = SVC(gamma='auto')\n",
    "# svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfcddb0",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6da3d715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=7000)\n",
    "# logistic_regression.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0daf27",
   "metadata": {},
   "source": [
    "## Tree-based Method: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9389e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=50, n_estimators=1000, n_jobs=-1,\n",
       "                       random_state=666)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classfication = RandomForestClassifier(n_estimators=1000, n_jobs=-1, max_depth=50,random_state=666)\n",
    "rf_classfication.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3554e174",
   "metadata": {},
   "source": [
    "## Tree-based Method: XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb9970e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qu4ntum/miniforge3/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/qu4ntum/miniforge3/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/qu4ntum/miniforge3/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:01:56] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:01:56] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1645117899018/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=5, min_child_weight=6, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=400, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgboost = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
    "             min_child_weight=6, monotone_constraints='()',\n",
    "       n_estimators=400, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
    "            reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
    "             tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "xgboost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d34effa",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd582b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch as T\n",
    "# class Net(T.nn.Module):\n",
    "#   def __init__(self):\n",
    "#     super(Net, self).__init__()\n",
    "#     self.hid1 = T.nn.Linear(8, 10)  # 8-(10-10)-1\n",
    "#     self.hid2 = T.nn.Linear(10, 10)\n",
    "#     self.oupt = T.nn.Linear(10, 1)\n",
    "\n",
    "#     T.nn.init.xavier_uniform_(self.hid1.weight)\n",
    "#     T.nn.init.zeros_(self.hid1.bias)\n",
    "#     T.nn.init.xavier_uniform_(self.hid2.weight)\n",
    "#     T.nn.init.zeros_(self.hid2.bias)\n",
    "#     T.nn.init.xavier_uniform_(self.oupt.weight)\n",
    "#     T.nn.init.zeros_(self.oupt.bias)\n",
    "\n",
    "#   def forward(self, x):\n",
    "#     z = T.relu(self.hid1(x))\n",
    "#     z = T.relu(self.hid2(z))\n",
    "#     z = self.oupt(z)  # no activation\n",
    "#     return z\n",
    "\n",
    "# bat_size = 10\n",
    "# net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5bb3bd",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e40e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluateing Logistic Regression\n",
    "# y_pred = logistic_regression.predict(X_test)\n",
    "# print(\"F1 Score: \",f1_score(y_test, y_pred, average='macro'))\n",
    "#print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "#F1 Score:  0.31860939565338836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cb65e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.39309758614852597\n",
      "Accuracy:  0.4028078689661149\n"
     ]
    }
   ],
   "source": [
    "#Evaluating RF\n",
    "y_pred = rf_classfication.predict(X_test)\n",
    "print(\"F1 Score: \",f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f865d3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating SVM\n",
    "# y_pred = svm.predict(X_test)\n",
    "# print(\"F1 Score: \",f1_score(y_test, y_pred, average='macro'))\n",
    "#print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "#F1 Score:  0.10067998398348055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0944dea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score:  0.39238348352691277\n",
      "Accuracy:  0.3948349077043071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qu4ntum/miniforge3/lib/python3.9/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "#Evaluating XG Boost\n",
    "y_pred = xgboost.predict(X_test)\n",
    "print(\"F1 Score: \",f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8968243c",
   "metadata": {},
   "source": [
    "# Conclusions and Findings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
